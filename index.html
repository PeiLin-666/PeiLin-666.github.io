<!DOCTYPE html>
<html lang="cx">

<head>
  <title>Pei Lin's Homepage - Shanghaitech University</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8" />
  <meta name="keywords" content="" />
  <script>
    addEventListener("load", function () {
      setTimeout(hideURLbar, 0);
    }, false);

    function hideURLbar() {
      window.scrollTo(0, 1);
    }
  </script>
  <!-- Custom Theme files -->
  <link href="css/bootstrap.css" type="text/css" rel="stylesheet" media="all">
  <link href="css/style.css" type="text/css" rel="stylesheet" media="all">
  <!-- font-awesome icons -->
  <link href="css/fontawesome-all.min.css" rel="stylesheet">
  <!-- //Custom Theme files -->
  <!-- online-fonts -->
  <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900" rel="stylesheet">
  <!-- //online-fonts -->
  <style>
	#news-box {
	height: 75px;
	overflow: hidden;
}
#news-box-more{
	font-size: 14px;
}

  </style>
</head>

<body>
  <div class="sidenav">
    <div class="side_top"> <img src="files/Paper/PeiLin2.PNG" width="75%" alt="news image" class="img-fluid navimg">
      <h1> Pei Lin - 林沛 <br>
        <!-- [<a href="files/CV/.pdf">Download CV</a>]<br> -->
        [<a href="mailto:linpei@shanghaitech.edu.cn">Email</a> | <a href="https://github.com/PeiLin-666">GitHub</a> |
        <!-- <a href="https://www.linkedin.com/in/fuqiang-zhao-190227208/">LinkedIn</a>] -->
        [<a href="https://scholar.google.com/citations?user=wR-6tm4AAAAJ&hl=zh-CN">Google Scholar</a>]
        [<a href="https://aideadlin.es/?sub=ML,CV,NLP,RO,SP,DM">Conference Timer</a>]

      </h1>
    </div>
    <!-- header -->
    <header>
      <div class="container-fluid px-5 ">
        <nav class="mnu mx-auto">
          <label for="drop" class="toggle">Menu</label>
          <input type="checkbox" id="drop">
          <ul class="menu">
            <!--<li><a href="index.html">Home</a></li-->
            <li class="mt-sm-0"><a href="#about" class="scroll">Bio</a></li>
            <li class="mt-sm-3"><a href="#publication" class="scroll">Publications</a></li>
            <li class="mt-sm-3"><a href="#experience" class="scroll">Experience</a></li>
            <li class="mt-sm-3"><a href="#skill" class="scroll">Skills</a></li>
          </ul>
        </nav>
      </div>
    </header>
  </div>
  <div class="main" id="about">
    <div class="banner-text-w3ls">
      <div>
        <div class="mx-auto text-left">
          <h1><strong>Pei Lin - 林沛</strong></h1>
          <h5>Master Candidate</h5>
          <h6>linpei@shanghaitech.edu.cn</h6><br>
          <h5><a href="http://www.shanghaitech.edu.cn/"><b>ShanghaiTech University - 上海科技大学 </b></a> - <a
              href="http://sist.shanghaitech.edu.cn/">SIST</a> - <a
              href="http://vic.shanghaitech.edu.cn/">VDI</a></h5> 

          Hi, now I am a master candidate student in <strong>computer science and technology</strong> at VRVC Lab, <a
            href="http://www.shanghaitech.edu.cn/">ShanghaiTech University</a>, advised by <a
            href="https://www.xu-lan.com">Prof. Lan Xu</a>. I also work close with <a
            href="http://www.yu-jingyi.com">Prof. Jingyi Yu</a> and <a
            href="https://faculty.sist.shanghaitech.edu.cn/faculty/wangjingya/">Prof. Jingya Wang</a>. I obtained my B.E. in <strong> computer science </strong> at <a
            href="http://www.shanghaitech.edu.cn/">ShanghaiTech University</a>.
            <br><br>
            I am passionate and interested in <strong>reconstruction, motion capture and motion generation</strong>.<br>
            My currrent research focuses on <strong>hands motion</strong> and try to find a way to <strong>combine the hands motion with LLM.</strong>
          </p>
          <li>Hand-hand & hand-object motion capture </li>
          <li>Hand-hand & hand-object motion generation</li>
          <li>Sign language recognition</li>
          <br>

          <h5><a href="https://rhythmo.cn/"><b>RhythMo Digital Technology Inc. - 域动数字科技有限公司 </b></a></h5> 
          I am also the co-founder of <a href="https://rhythmo.cn/"><strong>RhythMo</strong></a>.<br> 
          <strong>RhythMo</strong> aims to offer a light weight motion capture system for VR/AR/VTuber and help to map the motion in real world to virtual.
            <br>
          Here is our softwares:
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
                <img src="files/Paper/RhyLive.png" width="200" height="200" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
            </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
                <br>
                <h6><strong>RhyLive</strong>: The first motion capture app in mobile.<br></h6>
                <p>[<a href="https://apps.apple.com/us/app/rhylive/id1614348230">Apple Store</a>] 
                [<a href="https://rhythmo.cn/rhylive/">PC</a>] 
                </p>
            </div>
            <!-- .Service-content ends here -->
        </div>
        
        <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
                <img src="files/Paper/RhyVerse3.png" width="200" height="200" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
            </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
                <br>
                <h6><strong>RhyVerse</strong>: Make friends with your motion.<br></h6>
                <p>
                [<a href="https://store.steampowered.com/app/1954260/RhyVerse/">steam</a>] 
                </p>
            </div>
        </div>
          <br>
          <br>

        <!-- <p>
          <font color="#f33"><b>News!</b></font>
          </p>
           <div id="news-box"> -->
            
			<!-- <li>[2023.06]&ensp; I serve as ICCV 2023 reviewer, review 5 papers.</li> -->

		   <!-- </div>
		   <a id="news-box-more" href="javascript:;"style="font-size:16px;"><b>MORE >></b></a>
        </div> -->
      </div>
    </div>


    <!-- publications -->
    <section class="publication" id="publication">
      <div class="container-fluid py-lg-1">
        <h3 class="w3_head mb-5">Publications <font size ="5"></font></h3>
        <div class="col-lg-12">

          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/HandDiffuse.png" width="110%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
       
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>HandDiffuse</strong>: Generative Controllers for Two-Hand Interactions via Diffusion Models<br>
              </h4>
              <p><strong>Pei Lin</strong>, Sihang Xu, Hongdi Yang, Yiran Liu, Xin Chen, Jingya Wang, JIngyi Yu, Lan Xu<br>
              </p>
              <p>(<strong>Arxiv 2023</strong>)</p>
              <p>
                [<a href="https://handdiffuse.github.io">ProjectPage</a>]
                [<a href="https://arxiv.org/pdf/2312.04867.pdf">ArxivPage</a>]
                [<a href="https://github.com/HandDiffuse/HandDiffuse">Code</a>]
              </p>
            </div>
       
          </div>



          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/humannerf.png" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>HumanNeRF</strong>: Efficiently Generated Human Radiance Field from Sparse Inputs<br>
              </h4>
              <p>Fuqiang Zhao, Wei Yang, Jiakai Zhang, <strong>Pei Lin</strong>, Yingliang Zhang, Jingyi Yu, Lan Xu<br>
              </p>
              <p>(<strong>CVPR 2022</strong>)Conference on Computer Vision and Pattern Recognition</p>
              <!-- <p class="text-left">We propose SportsCap – the first approach for simultaneously capturing 3D human motions and understanding fine-grained actions from monocular challenging sports video input. </p> -->
              <p>[<a href="https://zhaofuq.github.io/humannerf/">ProjectPage</a>] 
                [<a href="https://arxiv.org/pdf/2112.02789.pdf">ArxivPage</a>]
                [<a href="https://zhaofuq.github.io/humannerf/">Code</a>]

              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>


          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/NeuralHumanFVV.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>NeuralHumanFVV</strong>: Efficiently Generated Human Radiance Field from Sparse Inputs<br>
              </h4>
              <p>Xin Suo, Yuheng Jiang, <strong>Pei Lin</strong>, Yingliang Zhang, Minye Wu, Kaiwen Guo, Lan Xu<br>
              </p>
              <p>(<strong>CVPR 2021</strong>)Conference on Computer Vision and Pattern Recognition</p>
              <!-- <p class="text-left">We propose SportsCap – the first approach for simultaneously capturing 3D human motions and understanding fine-grained actions from monocular challenging sports video input. </p> -->
              <p>[<a href="https://nowheretrix.github.io/neuralhumanFVV/">ProjectPage</a>] 
                [<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Suo_NeuralHumanFVV_Real-Time_Neural_Volumetric_Human_Performance_Rendering_Using_RGB_Cameras_CVPR_2021_paper.html">ArxivPage</a>]

              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>


          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <img 
                src="files/Paper/HOI.png" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4>Neural Free-Viewpoint Performance Rendering under Complex Human-object Interactions<br>
              </h4>
              <p>Guoxing Sun, Xin Chen, Yizhang Chen, Anqi Pang, <strong>Pei Lin</strong>, Yuheng Jiang, Lan Xu, Jingya Wang, Jingyi Yu<br>
              </p>
              <p>(<strong>ACM MM 2021 Oral</strong>)ACM Multimedia</p>
              <!-- <p class="text-left">We propose SportsCap – the first approach for simultaneously capturing 3D human motions and understanding fine-grained actions from monocular challenging sports video input. </p> -->
              <p>[<a href="https://sunshinnnn.github.io/HOI-FVV">ProjectPage</a>] 
                [<a href="https://arxiv.org/pdf/2108.00362.pdf">ArxivPage</a>]

              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>





          
      </div>
    </section>



    <!-- experience -->
    <section class="wedo" id="experience">
      <div class="experience">
        <h3 class="w3_head mb-5">Experience</h3>
        <div class="row service_w3top mt-5">
          <div class="col-xl-12">
            <div class="d-flex experience-box">
              <div class="icon"><span class="fa fa-briefcase"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="https://rhythmo.cn/">RhythMo Digital Technology Inc. - 上海域动数字科技有限公司</a></h4>
                  <h4> Jan. 2021 - Present</h4>
                </div>
                <h4> Co-founder</h4>
                <p>RhythMo aims to offer a light weight motion capture system for VR/AR/VTuber and help to map the motion in real world to virtual.
                   It was incubated from the Visual Data Intelligence (VDI) Center at ShanghaiTech, by a group of fearless PhD students with various expertise on motion capture and motion generation.</a></p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
            <div class="d-flex experience-box">
              <div class="icon"><span class="fa fa-briefcase"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://www.stereye.cn">Stereye Technology Inc. - 上海岱悟智能有限公司</a></h4>
                  <h4> Jun. 2020 - Sep.2020</h4>
                </div>
                <h4> R&amp;D Intern</h4>
                <p>I work as a part-time research and development intern at <a href="http://www.stereye.cn">Stereye
                    Technology Inc. </a></p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
          </div>
        </div>
        <h3 class="w3_head mb-5">Education</h3>
        <div class="row service_w3top mt-5">
          <div class="col-xl-12">
            <div class="d-flex experience-box">
              <div class="icon"> <span class="fa fa-graduation-cap"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University - 上海科技大学</a></h4>
                  <h4>Sep. 2020 - Present </h4>
                </div>
                <h4> Master Candidate</h4>
                <p>I am a Master Candidate on computer vision research, advised by <a href="http://xu-lan.com">Prof. Lan Xu</a> 
                  and developed a framework for hands motion generation and sign language recognition combined with LLM.</p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
            <div class="d-flex experience-box">
              <div class="icon"> <span class="fa fa-graduation-cap"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University - 上海科技大学</a></h4>
                  <h4>Sep. 2016 - Jul. 2020 </h4>
                </div>
                <h4> Bachelor </h4>
                <p>I obtained my B.E. in computer science at ShanghaiTech University.</p>
                <!-- <li>Outstanding Graduates of China University of Petroleum 2020</li>
                <li>First Prize of Shandong Software Design Competition 2018</li>
                <li>National Inspirational Scholarship 2017,2018</li>
                <li>Merit Student 2017,2018</li> -->
              </div>
              <!-- .Service-content ends here -->
            </div>
          </div>
        </div>
      </div>
    </section>

        <!-- Supervisors -->
    <!-- <section class="wedo" id="-Supervisors">
      <h3 class="w3_head col-md-12 mb-12"> Supervisors </h3>
      <div id="id4" style="clear:both"></div>
      <div class="col-md-5 col-12 people-content">
        <p class="banp mt-5"> <a href="http://www.yu-jingyi.com/">Prof. Jingyi Yu</a> - Supervisor </p>
        <li>IEEE Fellow</li>
        <li>Program chair of ICPR 2020 and CVPR 2021</li>
        <li>Executive Dean, SIST, ShanghaiTech University</li>
        <li>Founder, DGene Inc.</li>
        <li>Ph.D.'s degree, MIT, 2005</li>
      </div>

      <div id="id4" style="clear:both"></div>
    </section> -->

    <!-- //skill -->
    <section class="wedo" id="skill">
      <h3 class="w3_head mb-1">Skills </h3>
      <p class="banp mt-5"> Programming Languages</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> Python (Pytorch, Tensorflow, and so on.)</li>
        <li> <i class="fa-li fa fa-check"></i> C++ (OpenCV, CUDA and so on. )</li>
      </ul>
      <p class="banp mt-5"> Softwares</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> Visual Studio, Pycharm, Jupyter Notebook, Android Studio</li>
        <li> <i class="fa-li fa fa-check"></i> Matlab</li>
        <li> <i class="fa-li fa fa-check"></i> Blender</li>
        <li> <i class="fa-li fa fa-check"></i> Adobe Photoshop, Premiere</li>
      </ul>
      <p class="banp mt-5"> Languages</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> TOEFL   103 </li>
        <li> <i class="fa-li fa fa-check"></i> GRE     320</li>

      </ul>
      <p class="banp mt-5"> Others</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> Latex, Markdown</li>

      </ul>
      <!-- <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.?i=5ix9r8rqpnb&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script> -->
      <!-- <script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=59qpe4r4c9p&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script> -->
    </section>
    <!-- //skill -->
  </div>
  <script>
	var newsBoxMoreBtn = document.getElementById('news-box-more')
	var newsBox = document.getElementById('news-box');
	var flag = false;
	newsBoxMoreBtn.addEventListener('click',function(){
		flag = !flag;
		if(flag){
			newsBox.style.height = 'auto';
			newsBoxMoreBtn.innerHTML = 'CLOSE <<'
		}
		else{
			newsBox.style.height = '75px';
			newsBoxMoreBtn.innerHTML = 'MORE >>'
		}
		
	})
  </script>
</body>

</html>